---
title: "GTI Data Exploration"
author: "Stef Meliss"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen = 999)
# empty work space
rm(list = ls())

# define directory
dir <- getwd()

# load libraries
library(kableExtra)
library(ggplot2)
library(GGally)
library(dplyr)
library(corrplot)

# load in functions
devtools::source_url("https://github.com/stefaniemeliss/Global_Teaching_InSights/blob/main/functions.R?raw=TRUE")

```

```{css, echo=FALSE}
img {
  max-width:200%;
  height: auto;
}
```


```{r, include=F}
teach <- read.csv("data_raw/GTI-Teacher-Data.csv")
stud <- read.csv("data_raw/GTI-Student-Data.csv")
group <- "COUNTRY"
```


# Contents  

[Oppurtonity to learn (OTL)](#OTL)  
[Video component scores (VCOMP)](#VCOMP)  
[Video indicator scores (VIND)](#VIND)  


# Opportunity to learn (OTL) {#OTL}

Derived variables also include indices for opportunity to learn (OTL). There are three versions of each index: one based on teacher log responses (TL), one based on student post-questionnaire responses (SQB), and one based on artefact ratings (AR). 

These variables are named with a two- or three-part naming convention, indicating the type of index (OTL), the instrument the index is based on (TL, SQB, or AR), and the specific subtopic for the index (FUNCTIONS, REASONING, APPLIED, or ALGEBRA), if applicable. 

* FUNCTIONS = OTL for using quadratic functions  
* REASONING = OTL for reasoning about different types of quadratic equations  
* APPLIED = OTL for applying quadratic equations to real world contexts  
* ALGEBRA = OTL for algebraic procedures  

### OTL as reported in the teacher log  

OTL_TL variables are defined as the weighted count of the lessons documented in the teacher log which cover the rerspective type of OTL. A lesson was counted with weight 1 if the subtopic was given major focus (score = 2), with weight 0.5 if the subtopic was given minor focus (score = 1), and with weight 0 otherwise. 

* **TL03_SUM**: Subtopic coverage rating for handling expressions.  
* **TL04_SUM**: Subtopic coverage rating for binomial formulas.  
* **TL05_SUM**: Subtopic coverage rating for introducing some type of quadratic equations.  
* **TL06A_SUM**: Subtopic coverage rating for solving quadratic equations by completing the square. 
* **TL06B_SUM**: Subtopic coverage rating for solving quadratic equations by factorizing.  
* **TL06C_SUM**: Subtopic coverage rating for solving quadratic equations using the quadratic formula.  
* **TL06D_SUM**: Subtopic coverage rating for solving quadratic equations by graphical representation.  
* **TL07_SUM**: Subtopic coverage rating for discussing different cases of quadratic equations.  
* **TL08_SUM**: Subtopic coverage rating for quadratic functions.  
* **TL09_SUM**: Subtopic coverage rating for applications.  

The OTL_TL variables are a weighted sum of the subtopic coverage from the teacher log (see drop-down section below).  

* **OTL_TL_FUNCTIONS**: Weighted index of OTL for using quadratic functions, based on the teacher log. *Calculated as the weighted count of TL06D and TL08*.
* **OTL_TL_ALGEBRA**: Weighted index of OTL for algebraic operations, based on the teacher log. *Calculated as the weighted count of TL03, TL04, TL06A, TL06B, and TL06C*.
* **OTL_TL_REASONING**: Weighted index of OTL for reasoning about different types of quadratic equations, based on the teacher log. *Calculated as the weighted count of TL07*.
* **OTL_TL_APPLIED**: Weighted index of OTL for applying quadratic equations to real world contexts, based on the teacher log. *Calculated as the weighted count of TL09*.


The table below shows the descriptive statistics for the four OTL categories, averaged across all teachers irrespective of country.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|OTL_TL", names(teach))]

# compute descriptives
out <- do.call("rbind", apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describe(x)))
out$vars <- NULL
out <- round(out, 3)

# print in markdown
kbl(out, caption = "Descriptives of OTL_TL* using whole dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Additionally, means and standard errors for each OTL were computed separately for each country and plotted below.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=5, fig.width=6}
# compute descriptives for each country
out <- apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describeBy(x, group = tmp$COUNTRY, mat=TRUE))

# transform out (list of data.frames) into df
out <- Reduce(full_join,out)
out$item <- rep(names(tmp)[c(-1, -2)], each = length(unique(tmp$COUNTRY)))
out$vars <- NULL
out[, c(-1, -2)] <- round(out[, c(-1, -2)], 3)

# print in markdown
plt <- ggplot(data = out, aes(x = group1, y = mean, fill = group1)) +
  geom_bar(stat = "identity", width = 0.5) + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1) +
  theme + 
  scale_fill_manual(values = ambition_palette) + guides(fill=FALSE) +
  facet_wrap(vars(item), ncol = 1) +
  xlab("Country") + ylab("Average OTL (based on teacher log)") +
  labs(caption = "Error bars represent SE.") + theme(plot.caption = element_text(hjust=0)) +
  ggtitle("OTL (source: teacher log) seperately for each country")

plt
```

To identify any patterns among the OTL as reported in the teacher log, a scatter and correlation matrix was created.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=10, fig.width=10}
# change parameter for density plots
custom_dens <- function(data, mapping, ...) {
  ggplot(data = data, mapping=mapping) +
    geom_density(..., alpha = 0.5,linewidth = 1) +
    scale_x_continuous(limits = c(0,13))
}

costum_points <- function(data,mapping){
  ggplot(data = data, mapping = mapping)+
    geom_point()+
    scale_x_continuous(limits = c(0,13))+
    scale_y_continuous(limits = c(0,13))
}  


# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of OTL as reported in the teacher log") + 
  theme
```

> The scatterplot matrix generated using the teacher log data as source suggests that overall, different OTL categories are positively correlated with each other.



<details>
<summary> <b> Appendix: Subtopic coverage from the teacher log </b> </summary>



Derived variables for subtopic coverage from the teacher log were calculated by taking the weighted sum of subtopic coverage ratings, where a lesson was counted with weight 1 if the subtopic was covered fully, weight 0.5 if the subtopic was covered to a minor extent, and weight 0 if the subtopic was not covered at all.  

* **TL03_SUM**: Subtopic coverage rating for handling expressions.  
* **TL04_SUM**: Subtopic coverage rating for binomial formulas.  
* **TL05_SUM**: Subtopic coverage rating for introducing some type of quadratic equations.  
* **TL06A_SUM**: Subtopic coverage rating for solving quadratic equations by completing the square. 
* **TL06B_SUM**: Subtopic coverage rating for solving quadratic equations by factorizing.  
* **TL06C_SUM**: Subtopic coverage rating for solving quadratic equations using the quadratic formula.  
* **TL06D_SUM**: Subtopic coverage rating for solving quadratic equations by graphical representation.  
* **TL07_SUM**: Subtopic coverage rating for discussing different cases of quadratic equations.  
* **TL08_SUM**: Subtopic coverage rating for quadratic functions.  
* **TL09_SUM**: Subtopic coverage rating for applications.  

Note: If rating is missing for one subtopic coverage, it is missing consistently for all. This suggests that the teacher log might be missing completely from those teachers.  

The table below shows the descriptive statistics for each subtopic separately, averaged across all teachers irrespective of country.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|_SUM", names(teach))]

# compute descriptives
out <- do.call("rbind", apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describe(x)))
out$vars <- NULL
out <- round(out, 3)

# print in markdown
kbl(out, caption = "Descriptives of subtopic coverage using whole dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Additionally, means and standard errors for each subtopic were computed seperately for each country and plotted below.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=10, fig.width=6}
# compute descriptives for each country
out <- apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describeBy(x, group = tmp$COUNTRY, mat=TRUE))

# transform out (list of data.frames) into df
out <- Reduce(full_join,out)
out$item <- rep(names(tmp)[c(-1, -2)], each = length(unique(tmp$COUNTRY)))
out$vars <- NULL
out[, c(-1, -2)] <- round(out[, c(-1, -2)], 3)

# print in markdown
plt <- ggplot(data = out, aes(x = group1, y = mean, fill = group1)) +
  geom_bar(stat = "identity", width = 0.5) + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1) +
  theme + 
  scale_fill_manual(values = ambition_palette) + guides(fill=FALSE) +
  facet_wrap(vars(item), ncol = 1) +
  xlab("Country") + ylab("Average subtopic coverage (based on teacher log)") +
  labs(caption = "Error bars represent SE.") + theme(plot.caption = element_text(hjust=0)) +
  ggtitle("Subtopic coverage seperately for each country")

plt
```

The above graph suggests that teachers in some countries have given higher ratings of subtopic coverage in the teacher log regardless of the specific subtopic. To further investigate this, a sum score was computed (**TL_SUM**). As shown below, the overall subtopic coverage varies substantially between countries.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE}
dv = "TL_SUM"
tmp[, dv] <- rowSums(tmp[, c(-1, -2)])

# generate and print descriptive tables to markdown
table_desc(data = tmp,
           group_var = group,
           dep_var = dv)
```


To identify any patterns among the subtopic coverage, a scatter and correlation matrix was created.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=20, fig.width=20}
# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of subtopic coverage") + 
  theme
```

</details> 


### OTL as reported by the students in the post-questionnaire  

OTL_SQB variables are defined as class-level means of the variables related to each subtopic.  

In the questionnaire, students were asked: ***For each task please indicate (yes or no) whether you encountered these types of mathematical tasks.***  

* Plotting the graph of y = x².  
* Solving a problem like x²−4=0 by inspection.  
* Finding all values of x for which(x−4)(x+5)=0.  
* Using the binomial formula (a+b)²=a²+2ab+b² when solving a problem like x²+6x+9=0.  
* Solving any quadratic equation (example: 4x²+6x+3 = 0).  
* Using different ways when solving a quadratic equation.  
* Explaining when a quadratic equation has one, two or no solutions.  
* Checking if an equation like 2x²+3x+1 has any real solution.  
* Calculating the highest point of a ball that is thrown diagonally into the air.  
* Calculating the distance a car has travelled after a certain time of acceleration.  
* Finding the roots of a quadratic function.  

Depending on the OTL category, class-level means were calculated using different items.  

* **OTL_SQB**: Class-level mean for OTL related to the focal unit, based on the student post-questionnaire. Calculated as class-level mean of SQB07EA_rec to SQB07EK_rec.
* **OTL_SQB_FUNCTIONS**: Class-level mean for OTL for using quadratic functions, based on the student post-questionnaire. Calculated as class-level mean of SQB07EA_rec, SQB07EK_rec.
* **OTL_SQB_ALGEBRA**: Class-level mean for OTL for algebraic operations, based on the student post-questionnaire. Calculated as class-level mean of SQB07EB_rec, SQB07EC_rec, SQB07ED_rec, SQB07EE_rec, SQB07EF_rec.
* **OTL_SQB_REASONING**: Class-level mean for OTL for reasoning about different types of quadratic equations, based on the student post-questionnaire. Calculated as class-level mean of SQB07EG_rec, SQB07EH_rec.
* **OTL_SQB_APPLIED**: Class-level mean for OTL for applying quadratic equations to real world contexts, based on the student post-questionnaire. Calculated as class-level mean of SQB07EI_rec, SQB07_EJ_rec.


The table below shows the descriptive statistics for the four OTL categories, averaged across all teachers irrespective of country.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|OTL_SQB", names(teach))]

# compute descriptives
out <- do.call("rbind", apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describe(x)))
out$vars <- NULL
out <- round(out, 3)

# print in markdown
kbl(out, caption = "Descriptives of OTL_SQB* using whole dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

> The table data suggests that for each item in the questionnaire, the answer was recoded to be 1 if the student encountered the oppurtunity (and 0 otherwise), then the class-level mean was calculated per item, before summing up the respective class-level means for all items that together contribute to an OTL category.  

Additionally, means and standard errors for each OTL were computed separately for each country and plotted below.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=5, fig.width=6}
# compute descriptives for each country
out <- apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describeBy(x, group = tmp$COUNTRY, mat=TRUE))

# transform out (list of data.frames) into df
out <- Reduce(full_join,out)
out$item <- rep(names(tmp)[c(-1, -2)], each = length(unique(tmp$COUNTRY)))
out$vars <- NULL
out[, c(-1, -2)] <- round(out[, c(-1, -2)], 3)

# print in markdown
plt <- ggplot(data = out, aes(x = group1, y = mean, fill = group1)) +
  geom_bar(stat = "identity", width = 0.5) + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1) +
  theme + 
  scale_fill_manual(values = ambition_palette) + guides(fill=FALSE) +
  facet_wrap(vars(item), ncol = 1) +
  xlab("Country") + ylab("Average OTL (based on SQB)") +
  labs(caption = "Error bars represent SE.") + theme(plot.caption = element_text(hjust=0)) +
  ggtitle("OTL (source: students) seperately for each country")

plt
```

> Interestingly, the student perception seems less varied across countries than the teacher log data would suggest. 


To identify any patterns among the OTL as reported by the students, a scatter and correlation matrix was created.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=12, fig.width=12}
# change parameter for density plots
custom_dens <- function(data, mapping, ...) {
  ggplot(data = data, mapping=mapping) +
    geom_density(..., alpha = 0.5,linewidth = 1)
}

costum_points <- function(data,mapping){
  ggplot(data = data, mapping = mapping)+
    geom_point()
}  

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of OTL as reported in the student questionnaire") + 
  theme
```

> The scatterplot matrix generated using the student questionnaire response data as source suggests that there is a more mixed and nuanced pattern with respect to the question whether or not different OTL categories are  correlated with each other.


### OTL as observed in the classroom artefact ratings

All artefact sets were rated based on the presence of nine specific mathematical subtopics, aligned to the subtopics that were captured by student questionnaires and teacher logs. All components were scored dichotomously (1 = present, 0 = otherwise).  

* **SQE_COMP_SQUARE_RATE**: Solving quadratic equations by completing the square  
* **SQE_FACTORIZING_RATE**: Solving quadratic equations by factorising  
* **SQE_QUADRATIC_RATE**: Deriving the quadratic formula or solving quadratic equations by using the quadratic formula  
* **SQE_FIND_ROOT_RATE**: Solving quadratic equations by finding roots in a graphical representation  
* **FACTOR_EXP_RATE**: Factoring expressions  
* **DIFF_CASE_RATE**: Discussing different cases of ax2+bx+c depending on values of a,b and c  
* **EXPLORING_FUNCT_RATE**: Exploring quadratic functions  
* **EXAMINING_REL_RATE**: Examining the relationship between the value of the discriminant and the number of solutions to a quadratic equation  
* **APPLY_REAL_WORLD_RATE**: Applying mathematics to real life situations  

Classroom-level subtopic coverage scores were derived by averaging over raters and artefact sets. Score construction followed a two-step process: i) Average two raters' artefact-set level ratings to obtain artefact-set level average; ii) Average the artefact-set averages to obtain a classroom-level score.  

The OTL_AR* indices are then computed by calculating the summative indecx for across different ratings.  

* **OTL_AR**: Summative index of OTL related to the focal unit, based on classroom artefact ratings. Calculated as mean of FACTOR_EXP_RATE to APPLY_REAL_WORLD_RATE.
* **OTL_AR_FUNCTIONS**: Summative index of OTL for using quadratic functions, based on classroom artefact ratings. Calculated as mean of SQE_FIND_ROOT_RATE, EXPLORING_FUNCT_RATE.
* **OTL_AR_ALGEBRA**: Summative index of OTL for algebraic operations, based on classroom artefact ratings. Calculated as mean of FACTOR_EXP_RATE, SQE_COMP_SQUARE_RATE, SQE_FACTORIZING_RATE, SQE_QUADRATIC_RATE.
* **OTL_AR_REASONING**: Summative index of OTL for reasoning about different types of quadratic equations, based on classroom artefact ratings. Calculated as mean of DIFF_CASE_RATE, EXAMINING_REL_RATE.
* **OTL_AR_APPLIED**: Summative index of OTL for applying quadratic equations to real world contexts, based on classroom artefact ratings. Takes on the value of APPLY_REAL_WORLD_RATE.

The table below shows the descriptive statistics for the four OTL categories, averaged across all teachers irrespective of country.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|OTL_AR", names(teach))]

# compute descriptives
out <- do.call("rbind", apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describe(x)))
out$vars <- NULL
out <- round(out, 3)

# print in markdown
kbl(out, caption = "Descriptives of OTL_AR* using whole dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Additionally, means and standard errors for each OTL were computed separately for each country and plotted below.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=5, fig.width=6}
# compute descriptives for each country
out <- apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describeBy(x, group = tmp$COUNTRY, mat=TRUE))

# transform out (list of data.frames) into df
out <- Reduce(full_join,out)
out$item <- rep(names(tmp)[c(-1, -2)], each = length(unique(tmp$COUNTRY)))
out$vars <- NULL
out[, c(-1, -2)] <- round(out[, c(-1, -2)], 3)

# print in markdown
plt <- ggplot(data = out, aes(x = group1, y = mean, fill = group1)) +
  geom_bar(stat = "identity", width = 0.5) + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1) +
  theme + 
  scale_fill_manual(values = ambition_palette) + guides(fill=FALSE) +
  facet_wrap(vars(item), ncol = 1) +
  xlab("Country") + ylab("Average OTL (based on AR)") +
  labs(caption = "Error bars represent SE.") + theme(plot.caption = element_text(hjust=0)) +
  ggtitle("OTL (source: artefact ratings) seperately for each country")

plt
```

> Akin to the teacher log, there is a substantial amount of variation visible across countries. 


To identify any patterns among the OTL based on the artefact ratings, a scatter and correlation matrix was created.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=12, fig.width=12}
# change parameter for density plots
custom_dens <- function(data, mapping, ...) {
  ggplot(data = data, mapping=mapping) +
    geom_density(..., alpha = 0.5,linewidth = 1)
}

costum_points <- function(data,mapping){
  ggplot(data = data, mapping = mapping)+
    geom_point()
}  

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of OTL based on the artefact ratings") + 
  theme
```

> The scatterplot matrix generated using the artefact rating data as source suggests that there is a more mixed and nuanced pattern with respect to the question whether or not different OTL categories are  correlated with each other.  


### Intercorrelation of OTL as rated in by different sources

Below, scatterplot and correlation matrices are created for each category of OTL separately, using all three data sources.  

##### Functions

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|_FUNCTIONS", names(teach))]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of OTL for using quadratic functions") + 
  theme


```



##### Reasoning

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|_REASON", names(teach))]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of OTL for reasoning about different types of quadratic equations") + 
  theme


```

##### Applied

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|_APPLIED", names(teach))]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of OTL for applying quadratic equations to real world contexts") + 
  theme


```

##### Algebra

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|_ALGEBRA", names(teach))]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of OTL for algebraic procedures") + 
  theme


```

##### All OTLs from all sources

The plots above showed that different data sources are if any mildly correlated with each other. Lastly, a scatterplot and correlation matrix of using the data for all categories and sources was created to determine whether including all the variables into the model would cause issues of multicollinearity.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=20, fig.width=20}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|_FUNCTIONS|_REASONING|_APPLIED|_ALGEBRA", names(teach))]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of all OTL") + 
  theme


```





# Video component scores (VCOMP) {#VCOMP}

The components protocol involved rating three components per domain. All scores had a 4-point scale. The component scales were developed to mean that a segment assigned a rating of four was of higher quality than a segment assigned a 1. All scales were operationalised in the same way, which means it is expected that when looking across countries/economies, components generally would be positively correlated with one another and always be explainable by theory.

In order to decrease the cognitive demand of rating and improve accuracy, each lesson was segmented into 16-minute segments. Each of the 24 component codes were rated every 16 minutes by two randomly assigned raters. Each rater watched an entire lesson. Raters were not assigned to rate the same teacher more than once (within or across protocols) for their main study ratings.  
  
Classroom-level scores for any of the 24 component codes are derived by averaging over raters, segments, and lessons as described by the following sequence of steps:  
  
1. *Average the two raters’ segment-level ratings* for each segment to obtain *segment averages*.  
2. *Average over the segment averages* for all segments associated with a lesson to obtain a *lesson average*. (If a teacher only had one lesson, use this score as the classroom-level score.)  
3. *Average the two lesson averages* for a teacher to obtain the *classroom-level score*.  
  
Derived variables at classroom-level for video component scores take the form **VCOMP_[component]** where “component” is an alphanumeric code, composed of a two-letter code denoting the domain followed by a three-character code denoting the specific component.  
  
> Variable names follow the structure **VCOMP_[DOMAIN][1-3][COMPONENT]**.   
  
- AR = Assessment and Response to Student Understanding  
  1. ES = Eliciting Student Feedback
  2. TF = Teacher Feedback
  3. AI = Aligning Instruction  
- CE = Cognitive Engagement
  1. DS = Engagement in Cognitively Demanding Subject Matter
  2. MA = Multiple Approaches
  3. US = Understanding of Subject Matter  
- CM = Classroom Management  
  1. RT = Routines
  2. MN = Monitoring
  3. DS = Disruptions  
- DC = Discourse  
  1. ND = Nature of Discourse
  2. QT = Questioning
  3. EP = Explanations  
- QS = Quality of Subject Matter  
  1. EC = Explicit Connections
  2. PG = Explicit Patterns and Generalizations
  3. CT = Clarity  
- SE = Social-Emotional Support
  1. RP = Respect
  2. EW = Encouragement and Warmth
  3. RT = Risk-taking  

```{r, echo = F, results='asis'}
# read in data dict
tmp <- read.delim("misc/teacher_file_variables_vcomp_explanation.txt", header = T)

# create key
key <- tmp[, c("Variable", "Altname")]
key <- key[!key$Variable == "VCOMP_TOTC", ]

# print table
kbl(tmp) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```

The table below shows the descriptive statistics for all 18 video component scores, averaged across all teachers irrespective of country.  
  
It is important to note that for some/most components, the SD (and hence SE) as well as the range are fairly small. Based on how the classroom-level component scores are computed, a maximum range of 3 would be possible.

```{r, echo = F, results='asis', fig.align='center', warning=FALSE}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VCOMP", names(teach))]
# remove total score
tmp[, grep("TOT", names(tmp))] <- NULL

# compute descriptives
out <- do.call("rbind", apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describe(x)))
out <- round(out, 3)

out$vars <- row.names(out)
row.names(out) <- NULL
names(out)[names(out)=="vars"] <- "Variable"

out <- merge(key, out, by.x = "Variable", sort = F)

# print in markdown
kbl(out, caption = "Descriptives of VCOMP* using whole dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Additionally, means and standard errors for each video component score were computed separately for each country and plotted below.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=10, fig.width=8}
# compute descriptives for each country
out <- apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describeBy(x, group = tmp$COUNTRY, mat=TRUE))

# transform out (list of data.frames) into df
out <- Reduce(full_join,out)
out$item <- rep(names(tmp)[c(-1, -2)], each = length(unique(tmp$COUNTRY)))
names(out)[names(out)=="item"] <- "Variable"
out <- merge(key, out, by.x = "Variable", sort = F)

out$vars <- NULL
out[, c(-1, -2, -3)] <- round(out[, c(-1, -2, -3)], 3)

# add domain column 
out$domain <- substr(out$Variable, 7, 8)
out$domain <- recode(out$domain, 
                     AR = "Assessment and Response to Student Understanding", 
                     CE = "Cognitive Engagement",
                     CM = "Classroom Management",
                     DC = "Discourse",
                     QS = "Quality of Subject Matter",
                     SE = "Social-Emotional Support"
                     )
# out$domain <- recode(out$domain, 
#                      AR = "Assessment and Response to Student Understanding: 1ES / 2TF / 3AI", 
#                      CE = "Cognitive Engagement: 1DS / 2MA / 3US",
#                      CM = "Classroom Management: 1RT / 2MN / 3DS",
#                      DC = "Discourse: 1ND / 2QT / 3EP",
#                      QS = "Quality of Subject Matter: 1EC / 2PG / 3CT",
#                      SE = "Social-Emotional Support: 1RP / 2EW / 3RT"
#                      )
out$comp_no <- substr(out$Variable, 9, 9)
out$comp_name <- substr(out$Variable, 9, 11)

# add cords for label
out$y_cord <- 5

# print in markdown
plt <- ggplot(data = out, aes(x = comp_no, y = mean, fill = group1)) +
  geom_bar(stat = "identity", width = 0.5, position = position_dodge(width=0.8)) + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1, position = position_dodge(width=0.8)) +
  theme + 
  geom_label(
    aes(x = comp_no, y = y_cord, label = Altname, group = comp_no),
    check_overlap = T,
    vjust = 0.5, fill = "white"
  ) +
  scale_fill_manual(values = ambition_palette, name = "Country") + 
  facet_wrap(vars(domain), ncol = 1) +
  xlab("Component") + ylab("Classroom-level VCOMP score") +
  labs(caption = "Error bars represent SE.") + theme(plot.caption = element_text(hjust=0)) +
  ggtitle("Video component score seperately for each country") +
  theme(axis.text.x = element_blank())
plt

```

To identify any patterns among the video component scores, scatterplot and correlation matrices are created for each domain separately, using all three component scores.  


##### Assessment and Response to Student Understanding

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VCOMP_AR", names(teach))]

# rename variables
names(tmp)[c(-1, -2)] <- key$Altname[match(names(tmp),key$Variable)][c(-1, -2)]

# change parameter for density plots
custom_dens <- function(data, mapping, ...) {
  ggplot(data = data, mapping=mapping) +
    geom_density(..., alpha = 0.5,linewidth = 1) +
    scale_x_continuous(limits = c(1,4))
}

costum_points <- function(data,mapping){
  ggplot(data = data, mapping = mapping)+
    geom_point()+
    scale_x_continuous(limits = c(1,4))+
    scale_y_continuous(limits = c(1,4))
}  


# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix - Domain AR") + 
  theme


```

##### Cognitive Engagement

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VCOMP_CE", names(teach))]

# rename variables
names(tmp)[c(-1, -2)] <- key$Altname[match(names(tmp),key$Variable)][c(-1, -2)]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix - Domain CE") + 
  theme


```

##### Classroom Management

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VCOMP_CM", names(teach))]

# rename variables
names(tmp)[c(-1, -2)] <- key$Altname[match(names(tmp),key$Variable)][c(-1, -2)]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix - Domain CM") + 
  theme


```

##### Discourse

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VCOMP_DC", names(teach))]

# rename variables
names(tmp)[c(-1, -2)] <- key$Altname[match(names(tmp),key$Variable)][c(-1, -2)]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix - Domain DC") + 
  theme


```

##### Quality of Subject Matter

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VCOMP_QS", names(teach))]

# rename variables
names(tmp)[c(-1, -2)] <- key$Altname[match(names(tmp),key$Variable)][c(-1, -2)]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix - Domain QS") + 
  theme


```

##### Social-Emotional Support

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.height=6, fig.width=6}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VCOMP_SE", names(teach))]

# rename variables
names(tmp)[c(-1, -2)] <- key$Altname[match(names(tmp),key$Variable)][c(-1, -2)]

# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points)) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix - Domain SE") + 
  theme


```

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.width=10, fig.height=10}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VCOMP", names(teach))]
# remove total score
tmp[, grep("TOT", names(tmp))] <- NULL

# rename variables
names(tmp)[c(-1, -2)] <- key$Altname[match(names(tmp),key$Variable)][c(-1, -2)]

# remove T_ID and Country
desc <- tmp[, c(-1, -2)]

# compute correlation matrix
out <- round(psych::corr.test(desc)$r, 2)

# # print table
# kbl(out, caption = "Intercorrelations between video component scores across countries") %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
#   add_header_above(c(" " = 1, "Domain AR" = 3, "Domain CE" = 3, "Domain CM" = 3, "Domain DC" = 3, "Domain QS" = 3, "Domain SE" = 3)) %>%
#   column_spec(1, border_right=T) %>%
#   column_spec(4, border_right=T) %>%
#   column_spec(7, border_right=T) %>%
#   column_spec(10, border_right=T) %>%
#   column_spec(13, border_right=T) %>%
#   column_spec(16, border_right=T) %>%
#   pack_rows("Domain AR", 1, 3) %>%
#   pack_rows("Domain CE", 4, 6) %>%
#   pack_rows("Domain CM", 7, 9) %>%
#   pack_rows("Domain DC", 10, 12) %>%
#   pack_rows("Domain QS", 13, 15) %>%
#   pack_rows("Domain SE", 16, 18)

cat("\n\n")
cat("##### Correlation matrix (all countries)")
cat("\n")
cat("For the correlation matrix, data from all countries was pooled. If a p-value is larger than 0.05, then the corresponding correlation value is crossed out. The upper triangular matrix was adjusted for multiple testing.\n")
corrplot(out, 
         p.mat = psych::corr.test(desc)$p, sig.level = .05, #insig = "p-value",
         method = 'shade', addCoef.col = 'black', number.font = 2, type = 'full', diag = T,
         tl.col = "black", number.cex = 1, tl.cex = 1, cl.cex = 1) 


```


The Technical Report [Chapter 19](https://web-archive.oecd.org/2021-03-10/578535-GTI-TechReport-Chapter19.pdf) describes that the large negative correlations (i.e., < -0.2) associated with the Risk Taking component of the Socio-Emotional Support domain suggest that Risk Taking may be functioning in an undesirable, inconsistently normative way across countries/economies.  

<details>
<summary> <b> Further elaboration on risk taking </b> </summary>


"This is operationalised as being more able to be learners who seek guidance and/or voluntarily share their private mathematical thinking publicly in their classrooms. During development, the countries/economies and International Consortium noticed that sometimes the social norms in the classroom were consistent with this idea that more socially safe classrooms were characterised by students’ seeking guidance and sharing their ideas. There were however, some classrooms in which norms around classroom participation were teacher-centred and there were not opportunities for students to seek guidance or volunteer to share their thinking. For example, in these classrooms, the teacher might not have students raise their hands to seek guidance during pair or individual work and instead, the teacher would circulate and eventually check in with each student in the room. Students appeared to hold their questions until the teacher arrived at their desk. In classrooms where there was such a (reasonable) norm, there might be few opportunities for students to volunteer to share publicly or seek guidance, thus scoring low on Risk Taking, despite the classroom being a safe emotional space to take risks."

</details>
  
Further, the Clarity component of the Quality of Subject Matter had five negative small negative correlations (i.e., < -0.10) with other components. On a theoretical level, clarity should not have negatively correlated with the other components and the pattern was inconsistent across countries. This divergent and moderately strong pattern indicates Clarity did not operate as intended at the global level and therefore, it was dropped for use in subsequent analyses and in the policy report.   

> Of note: It appears as if for the Clarity component, the criteria was applied regardless of whether the correlations differ significantly from zero. As shown in the correlation matrix, most correlation coefficients < -0.1 are not significant when correcting for multiple testing.  


<details>
<summary> <b> Appendix: Scatterplot and correlation matrix of video component scores for all countries separately </b> </summary>


```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=30, fig.width=30}
# intercorrelation plot
ggpairs(tmp, columns = 3:ncol(tmp), mapping = aes(fill = COUNTRY, col = COUNTRY), diag = list(continuous = custom_dens), lower = list(continuous = costum_points),
        showStrips = T) + 
  scale_color_manual(values = ambition_palette) + scale_fill_manual(values = ambition_palette) +
  ggtitle("Scatterplot and correlation matrix of video component scores") + 
  theme
```

</details>



# Video indicator scores (VIND) {#VIND}

The indicator codes are grouped roughly into five of the six teaching practice domains. There are no indicators for the Assessment of and Responses to Student Understanding domain. Unlike the components, which were all rated on a 1 to 4 scale, the rating scale varies across indicators from 1-2 to 1-4, as indicated by the “Max Rating” column.  
  
Indicators were not designed to be aggregated up to the domain level. They are not the same grain size as one another, nor are they on the same scales. Further, they reasonably might be associated with another domain than the domain into which they are grouped.  
  
To reduce cognitive load and to improve rating accuracy, each lesson was divided into eight-minute segments for rating indicators. Raters rated all indicator codes for each segment. 
  
In total, there are 38 classroom indicators. Indicators were aggregated to the teacher level in four different ways. For six indicators, more than one aggregration method was applied. The aggregation that may be more appropriate is denoted with asterisk/printed in boldThe table below shows the descriptive statistics for all 18 video component scores, averaged across all teachers irrespective of country.

.  
  
Aggregation methods:  
  
* **Basic average**: The basic average followed the same aggregation method as for components:  
  1. Average the two raters’ segment-level ratings for an indicator code for the same segment to obtain segment averages.  
  2. Average over all the segment averages from step 1 for a single lesson to obtain a lesson average. (If a class only has one recorded lesson, use this score as the classroom score.)  
  3. Average over the two lesson averages for a teacher to obtain the classroom-level score.  
* **Percent present**: The percent present aggregation approach summarises the extent that an indicator code was used. It is the average percentage of lesson segments (over raters and lessons) that *a code was present or used*. The percent present aggregation method is only appropriate for indicator codes for which a rating of 1 indicates not present and all other ratings indicate some degree of use. Specifically, the percent present is found as follows:  
  1. For a lesson, count the number of segments a rater did not assign a 1, which indicates “not present”. Divide this count by the total number of segments in the lesson to obtain the proportion present for a rater for a lesson. Multiply by 100 to transform the proportion to a percent.  
  2. Average the two raters’ percentages present (from step 1) for a lesson to obtain the average percent present for the lesson. (If a class only has one recorded lesson, use this score as the classroom score.)  
  3. Average the two lesson averages (from step 2) for a teacher to obtain the average percent present for the classroom.  
* **Highest achieved**: The highest achieved aggregation approach describes the highest rating a classroom achieved for a lesson on average (over raters and lessons) for a particular indicator code. All of these codes are for practices that are rarely implemented in classrooms and not necessarily expected to be implemented throughout the entire lesson. Otherwise, if basic averages were used, then low ratings would likely dominate the averages and there would be little variance in the teacher scores, making it difficult to distinguish among teachers who used the practice at all in their lesson and those who never did. Specifically, the highest achieved classroom score is found as follows:  
  1. For a lesson and a particular rater, identify the highest assigned rating over all segments.  
  2. Average the two raters’ highest achieved lesson scores (from step 1) for the same lesson. (If a class only has one recorded lesson, use this score as the classroom score.)  
  3. Average the two lesson highest achieved scores (from step 2) for a class to obtain the highest achieved score for the classroom.  
* **Lowest achieved**: This aggregation approach is useful for indicator codes that tend to receive high ratings for all classes and lessons to be able to better distinguish among classrooms (i.e., accuracy to identify teachers who ever had inaccurate moments in their lesson). The lowest achieved aggregation approach is similar to the highest achieved aggregation approach, but instead of taking the highest rating for a lesson, the lowest rating is used, as described below:  
  1. For a lesson and a particular rater, identify the lowest assigned rating over all segments.  
  2. Average the two raters’ lowest achieved lesson scores (from step 1) for the same lesson. (If a teacher only has one lesson, use this score as the teacher score.)  
  3. Average the two lesson lowest achieved scores (from step 2) for a class to obtain the lowest achieved score for the classroom.  
  
Derived variables for video indicator scores take the form **VIND[_indicator]**, where indicator is an alphanumeric code, composed of a two-letter code denoting the domain, a three-character code denoting the specific indicator, and a 3-6 letter code indicating the specific aggregation method used (PCT, MAX, MIN, LESAVG, LESAVGNO1).  
  
> Variable names follow the structure **VCOMP_[DOMAIN][INDICATOR][AGGREGATION METHOD]**.  
  



```{r, echo = F, results='asis', fig.align='center', warning=FALSE}
# read in data dict
tmp <- read.delim("misc/teacher_file_variables_vind_explanation.txt", header = T)

# create key
key <- tmp[, c("Variable", "Altname", "Max.rating")]

# print table
kbl(tmp) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

The table below shows the descriptive statistics for all 44 video indicator scores, averaged across all teachers irrespective of country.  
  
It is important to note that for some indicators, the SD (and hence SE) as well as the range are fairly small. Because no common rating scale and aggregation method was applied across all indicators, the maximum rating that an indicator could have had at segment level was added. However, for those indicators that were aggregated as percentage present (i.e., those were the variable name ends in PCT), the maximum possible range is 0-1. The maximum possible aggregrated score is hence included in the table as well.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VIND", names(teach))]

# reorder columns
#tmp <- tmp[, c("T_ID", "COUNTRY", key$Variable)]

# compute descriptives
out <- do.call("rbind", apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describe(x)))
out <- round(out, 3)

out$vars <- row.names(out)
row.names(out) <- NULL
names(out)[names(out)=="vars"] <- "Variable"

# add altname and max possible rating
key$Max.value.agg <- ifelse(grepl("PCT", key$Variable), 1, key$Max.rating)
out <- merge(key, out, by.x = "Variable", sort = F)

# print in markdown
kbl(out, caption = "Descriptives of VIND* using whole dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Additionally, means and standard errors for each video component score were computed separately for each country and plotted below.  

```{r, echo = F, results='asis', fig.align='center', warning=FALSE, message = F, fig.height=35, fig.width=6}
# compute descriptives for each country
out <- apply(tmp[, c(-1, -2)], MARGIN = 2, function(x) psych::describeBy(x, group = tmp$COUNTRY, mat=TRUE, digits = 3))

# transform out (list of data.frames) into df
out <- data.table::rbindlist(out, idcol = "Variable")
out <- merge(key, out, by.x = "Variable", sort = F)

# make factor
out$Altname_f <- factor(out$Altname, levels = c(key$Altname))
key$Altname_f <- factor(key$Altname, levels = c(key$Altname))

out$vars <- NULL

# add domain column 
out$domain <- substr(out$Variable, 6, 7)
out$domain <- recode(out$domain, 
                     AR = "Assessment and Response to Student Understanding", 
                     CE = "Cognitive Engagement",
                     CM = "Classroom Management",
                     DC = "Discourse",
                     QS = "Quality of Subject Matter",
                     SE = "Social-Emotional Support"
                     )

# print in markdown
plt <- ggplot(data = out, aes(x = group1, y = mean, fill = group1)) +
  geom_bar(stat = "identity", width = 0.5) + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1) +
  geom_hline(data = key, aes(yintercept = Max.value.agg), col = "black", type = "dashed") +
  theme + 
  scale_fill_manual(values = ambition_palette) + guides(fill=FALSE) +
  facet_wrap(vars(Altname_f), ncol = 1, scales = "free_y") +
  xlab("Country") + ylab("Classroom-level VIND score") +
  labs(caption = "Error bars represent SE.") + theme(plot.caption = element_text(hjust=0)) +
  ggtitle("Video indicator score seperately for each country")

plt

```


```{r, echo = F, results='asis', fig.align='center', warning=FALSE, fig.width=22, fig.height=22}
# select relevant variables and save in a df
tmp <- teach[, grep("T_ID|COUNTRY|VIND", names(teach))]

# rename variables
names(tmp)[c(-1, -2)] <- key$Altname[match(names(tmp),key$Variable)][c(-1, -2)]

# remove T_ID and Country
desc <- tmp[, c(-1, -2)]

# reorder columns
desc <- desc[, c(key$Altname)]

# compute correlation matrix
out <- round(psych::corr.test(desc)$r, 2)


cat("\n\n")
cat("##### Correlation matrix (all countries)")
cat("\n")
cat("For the correlation matrix, data from all countries was pooled. If a p-value is larger than 0.05, then the corresponding correlation value is crossed out. The upper triangular matrix was adjusted for multiple testing.\n")
corrplot(out, 
         p.mat = psych::corr.test(desc)$p, sig.level = .05, #insig = "p-value",
         method = 'shade', addCoef.col = 'black', number.font = 2, type = 'full', diag = T,
         tl.col = "black", number.cex = 1, tl.cex = 1, cl.cex = 1) 


```
